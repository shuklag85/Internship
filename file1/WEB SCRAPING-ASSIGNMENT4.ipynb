{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02915937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164555d3",
   "metadata": {},
   "source": [
    "Scrape  the  \n",
    "details  of  \n",
    "most  viewed  videos  on  \n",
    "YouTube  \n",
    "from  Wikipedia.  \n",
    "Url \n",
    "= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:  A) \n",
    "Rank   \n",
    "B) Name   \n",
    "C) Artist   \n",
    "D) Upload date   \n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999610c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37a7afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video_Name: Baby Shark Dance\n",
      "Uploader: Pinkfong Baby Shark - Kids' Songs & Stories\n",
      "Views: 14.32\n",
      "Date: June 17, 2016\n",
      "\n",
      "Video_Name: Despacito\n",
      "Uploader: Luis Fonsi\n",
      "Views: 8.41\n",
      "Date: January 12, 2017\n",
      "\n",
      "Video_Name: Johny Johny Yes Papa\n",
      "Uploader: LooLoo Kids - Nursery Rhymes and Children's Songs\n",
      "Views: 6.89\n",
      "Date: October 8, 2016\n",
      "\n",
      "Video_Name: Bath Song\n",
      "Uploader: Cocomelon - Nursery Rhymes\n",
      "Views: 6.66\n",
      "Date: May 2, 2018\n",
      "\n",
      "Video_Name: Shape of You\n",
      "Uploader: Ed Sheeran\n",
      "Views: 6.23\n",
      "Date: January 30, 2017\n",
      "\n",
      "Video_Name: See You Again\n",
      "Uploader: Wiz Khalifa\n",
      "Views: 6.22\n",
      "Date: April 6, 2015\n",
      "\n",
      "Video_Name: Wheels on the Bus\n",
      "Uploader: Cocomelon - Nursery Rhymes\n",
      "Views: 6.01\n",
      "Date: May 24, 2018\n",
      "\n",
      "Video_Name: Phonics Song with Two Words\n",
      "Uploader: ChuChu TV Nursery Rhymes & Kids Songs\n",
      "Views: 5.75\n",
      "Date: March 6, 2014\n",
      "\n",
      "Video_Name: Uptown Funk\n",
      "Uploader: Mark Ronson\n",
      "Views: 5.18\n",
      "Date: November 19, 2014\n",
      "\n",
      "Video_Name: Gangnam Style\n",
      "Uploader: Psy\n",
      "Views: 5.10\n",
      "Date: July 15, 2012\n",
      "\n",
      "Video_Name: Learning Colors – Colorful Eggs on a Farm\n",
      "Uploader: Miroshka TV\n",
      "Views: 5.09\n",
      "Date: February 27, 2018\n",
      "\n",
      "Video_Name: Dame Tu Cosita\n",
      "Uploader: Ultra Records\n",
      "Views: 4.59\n",
      "Date: April 5, 2018\n",
      "\n",
      "Video_Name: Masha and the Bear\n",
      "Uploader: Get Movies\n",
      "Views: 4.57\n",
      "Date: January 31, 2012\n",
      "\n",
      "Video_Name: Axel F\n",
      "Uploader: Crazy Frog\n",
      "Views: 4.45\n",
      "Date: June 16, 2009\n",
      "\n",
      "Video_Name: Sugar\n",
      "Uploader: Maroon 5\n",
      "Views: 4.02\n",
      "Date: January 14, 2015\n",
      "\n",
      "Video_Name: Baa Baa Black Sheep\n",
      "Uploader: Cocomelon - Nursery Rhymes\n",
      "Views: 4.01\n",
      "Date: June 25, 2018\n",
      "\n",
      "Video_Name: Counting Stars\n",
      "Uploader: OneRepublic\n",
      "Views: 4.00\n",
      "Date: May 31, 2013\n",
      "\n",
      "Video_Name: Lakdi Ki Kathi\n",
      "Uploader: Jingle Toons\n",
      "Views: 3.98\n",
      "Date: June 14, 2018\n",
      "\n",
      "Video_Name: Roar\n",
      "Uploader: Katy Perry\n",
      "Views: 3.98\n",
      "Date: September 5, 2013\n",
      "\n",
      "Video_Name: Waka Waka (This Time for Africa)\n",
      "Uploader: Shakira\n",
      "Views: 3.89\n",
      "Date: June 4, 2010\n",
      "\n",
      "Video_Name: Sorry\n",
      "Uploader: Justin Bieber\n",
      "Views: 3.78\n",
      "Date: October 22, 2015\n",
      "\n",
      "Video_Name: Shree Hanuman Chalisa\n",
      "Uploader: T-Series Bhakti Sagar\n",
      "Views: 3.77\n",
      "Date: May 10, 2011\n",
      "\n",
      "Video_Name: Humpty the train on a fruits ride\n",
      "Uploader: Kiddiestv Hindi - Nursery Rhymes & Kids Songs\n",
      "Views: 3.76\n",
      "Date: January 26, 2018\n",
      "\n",
      "Video_Name: Thinking Out Loud\n",
      "Uploader: Ed Sheeran\n",
      "Views: 3.75\n",
      "Date: October 7, 2014\n",
      "\n",
      "Video_Name: Perfect\n",
      "Uploader: Ed Sheeran\n",
      "Views: 3.70\n",
      "Date: November 9, 2017\n",
      "\n",
      "Video_Name: Dark Horse\n",
      "Uploader: Katy Perry\n",
      "Views: 3.70\n",
      "Date: February 20, 2014\n",
      "\n",
      "Video_Name: Let Her Go\n",
      "Uploader: Passenger\n",
      "Views: 3.64\n",
      "Date: July 25, 2012\n",
      "\n",
      "Video_Name: Faded\n",
      "Uploader: Alan Walker\n",
      "Views: 3.60\n",
      "Date: December 3, 2015\n",
      "\n",
      "Video_Name: Girls Like You\n",
      "Uploader: Maroon 5\n",
      "Views: 3.58\n",
      "Date: May 31, 2018\n",
      "\n",
      "Video_Name: Lean On\n",
      "Uploader: Major Lazer Official\n",
      "Views: 3.57\n",
      "Date: March 22, 2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Selenium WebDriver (make sure to specify the path to your WebDriver)\n",
    "driver = webdriver.Chrome()  # Update with your WebDriver (e.g., webdriver.Chrome() for Chrome)\n",
    "\n",
    "# Open the URL in the WebDriver\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "driver.maximize_window()\n",
    "\n",
    "# Wait for the table to load (using explicit wait)\n",
    "time.sleep(5)\n",
    "table = driver.find_elements(By.XPATH, '//table[@class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr')\n",
    "#print(table)\n",
    "for t in table:\n",
    "    columns=t.find_elements(By.TAG_NAME,'td')\n",
    "    #print(columns)\n",
    "    if len(columns) >= 4:\n",
    "            Video_Name = columns[0].find_element(By.TAG_NAME,'a').text.strip()\n",
    "            Uploader = columns[1].text.strip()\n",
    "            Views = columns[2].text.strip()\n",
    "            Date = columns[3].text.strip()\n",
    "            \n",
    "            \n",
    "            # Print the extracted data\n",
    "            print(\"Video_Name:\", Video_Name)\n",
    "            print(\"Artist:\", Uploader)\n",
    "            print(\"Views:\", Views)\n",
    "            print(\"Upload_Date:\", Date)\n",
    "            \n",
    "            print()  # Print empty line for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce05ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749f1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd0aa6b0",
   "metadata": {},
   "source": [
    "## BCCI Project \n",
    "Scrape the details team India’s international fixtures from bcci.tv.   \n",
    "Url = https://www.bcci.tv/.   \n",
    "You need to find following details:   \n",
    "A) Series   \n",
    "B) Place   \n",
    "C) Date   \n",
    "D) Time   \n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4863e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6a59853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>2 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>6 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024</td>\n",
       "      <td>Sylhet International Cricket Stadium,</td>\n",
       "      <td>9 MAY, 2024</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>5 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>9 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Nassau County International Cricket Stadium,</td>\n",
       "      <td>12 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS T20 WORLD CUP 2024</td>\n",
       "      <td>Central Broward Park &amp; Broward County Stadium,...</td>\n",
       "      <td>15 JUNE, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Series  \\\n",
       "0  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "1  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "2  INDIA WOMEN TOUR OF BANGLADESH T20 SERIES 2024   \n",
       "3                     ICC MENS T20 WORLD CUP 2024   \n",
       "4                     ICC MENS T20 WORLD CUP 2024   \n",
       "5                     ICC MENS T20 WORLD CUP 2024   \n",
       "6                     ICC MENS T20 WORLD CUP 2024   \n",
       "7                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "8                     INDIA TOUR OF ZIMBABWE 2024   \n",
       "\n",
       "                                               Place           Date  \\\n",
       "0              Sylhet International Cricket Stadium,    2 MAY, 2024   \n",
       "1              Sylhet International Cricket Stadium,    6 MAY, 2024   \n",
       "2              Sylhet International Cricket Stadium,    9 MAY, 2024   \n",
       "3       Nassau County International Cricket Stadium,   5 JUNE, 2024   \n",
       "4       Nassau County International Cricket Stadium,   9 JUNE, 2024   \n",
       "5       Nassau County International Cricket Stadium,  12 JUNE, 2024   \n",
       "6  Central Broward Park & Broward County Stadium,...  15 JUNE, 2024   \n",
       "7                                Harare Sports Club,   6 JULY, 2024   \n",
       "8                                Harare Sports Club,   7 JULY, 2024   \n",
       "\n",
       "          Time  \n",
       "0  3:30 PM IST  \n",
       "1  3:30 PM IST  \n",
       "2  3:30 PM IST  \n",
       "3  8:00 PM IST  \n",
       "4  8:00 PM IST  \n",
       "5  8:00 PM IST  \n",
       "6  8:00 PM IST  \n",
       "7  8:00 PM IST  \n",
       "8  8:00 PM IST  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "# URL of the BCCI homepage\n",
    "url = \"https://www.bcci.tv/\"\n",
    "\n",
    "# Initialize Selenium WebDriver (specify the path to your WebDriver)\n",
    "driver = webdriver.Chrome()  # Assuming Chrome WebDriver is used\n",
    "driver.get('https://www.bcci.tv/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "Fixture=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[2]/ul/div[1]/a[2]')\n",
    "Fixture.click()\n",
    "time.sleep(5)\n",
    "\n",
    "#Main=driver.find_element(By.XPATH,'//section[@class=\"w-100 position-relative gap-between-section pb-0\"]')\n",
    "Table=driver.find_elements(By.XPATH,'//div[@id=\"match-card\"]')\n",
    "\n",
    "Series  =[] \n",
    "Place   =[]\n",
    "Date   =[]\n",
    "Time   =[]\n",
    "\n",
    "for i in Table:\n",
    "    Sers=i.find_element(By.XPATH,'div/div/div/h5')\n",
    "    plc=i.find_element(By.XPATH,'div[2]/div/span[1]')\n",
    "    Dt=i.find_element(By.XPATH,'div/div/div/div[2]/div')\n",
    "    Tm=i.find_element(By.XPATH,'div/div/div/div[2]/div[2]')\n",
    "\n",
    "    Series.append(Sers.text) \n",
    "    Place.append(plc.text)   \n",
    "    Date.append(Dt.text)  \n",
    "    Time .append(Tm.text)\n",
    "# Create DataFrame from scraped data\n",
    "df = pd.DataFrame({\n",
    "    'Series': Series,\n",
    "\n",
    "    'Place': Place,\n",
    "    'Date': Date,\n",
    "    'Time': Time\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f12358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd4c5baf",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.   \n",
    "Url = http://statisticstimes.com/   \n",
    "You have to find following details: A) Rank   \n",
    "B) State   \n",
    "C) GSDP(21-22)- at current prices   \n",
    "D) GSDP(22.23)- at current prices   \n",
    "E) Share(21-22)   \n",
    "F) GDP($ billion)   \n",
    "Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a5ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2251e0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDP_21_22</th>\n",
       "      <th>GDP_22_23</th>\n",
       "      <th>Share_21_22</th>\n",
       "      <th>GDP_Billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.17%</td>\n",
       "      <td>414.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.78%</td>\n",
       "      <td>276.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,978,094</td>\n",
       "      <td>2,269,995</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>264.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,975,595</td>\n",
       "      <td>2,258,040</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>263.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,928,683</td>\n",
       "      <td>2,230,609</td>\n",
       "      <td>8.17%</td>\n",
       "      <td>257.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,329,238</td>\n",
       "      <td>1,531,758</td>\n",
       "      <td>5.63%</td>\n",
       "      <td>177.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,193,489</td>\n",
       "      <td>1,365,849</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>159.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,148,471</td>\n",
       "      <td>1,303,524</td>\n",
       "      <td>4.87%</td>\n",
       "      <td>153.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,124,204</td>\n",
       "      <td>1,308,034</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>150.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,092,964</td>\n",
       "      <td>1,246,471</td>\n",
       "      <td>4.63%</td>\n",
       "      <td>145.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>934,542</td>\n",
       "      <td>1,046,188</td>\n",
       "      <td>3.96%</td>\n",
       "      <td>124.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>881,336</td>\n",
       "      <td>1,014,688</td>\n",
       "      <td>3.73%</td>\n",
       "      <td>117.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>868,905</td>\n",
       "      <td>984,055</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>116.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>662,886</td>\n",
       "      <td>753,177</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>88.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.76%</td>\n",
       "      <td>86.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>617,192</td>\n",
       "      <td>676,164</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>411,454</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>410,525</td>\n",
       "      <td>464,399</td>\n",
       "      <td>1.74%</td>\n",
       "      <td>54.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.52%</td>\n",
       "      <td>47.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>267,143</td>\n",
       "      <td>303,781</td>\n",
       "      <td>1.13%</td>\n",
       "      <td>35.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>193,352</td>\n",
       "      <td>224,226</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>25.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>172,162</td>\n",
       "      <td>191,728</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>22.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>84,266</td>\n",
       "      <td>93,672</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>11.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>46,096</td>\n",
       "      <td>54,285</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>6.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>43,810</td>\n",
       "      <td>49,643</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>34,775</td>\n",
       "      <td>39,630</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,038</td>\n",
       "      <td>35,643</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  GDP_21_22  GDP_22_23 Share_21_22  \\\n",
       "0     1                Maharashtra  3,108,022          -      13.17%   \n",
       "1     2                 Tamil Nadu  2,071,286  2,364,514       8.78%   \n",
       "2     3                  Karnataka  1,978,094  2,269,995       8.38%   \n",
       "3     4              Uttar Pradesh  1,975,595  2,258,040       8.37%   \n",
       "4     5                    Gujarat  1,928,683  2,230,609       8.17%   \n",
       "5     6                West Bengal  1,329,238  1,531,758       5.63%   \n",
       "6     7                  Rajasthan  1,193,489  1,365,849       5.06%   \n",
       "7     8             Andhra Pradesh  1,148,471  1,303,524       4.87%   \n",
       "8     9                  Telangana  1,124,204  1,308,034       4.76%   \n",
       "9    10             Madhya Pradesh  1,092,964  1,246,471       4.63%   \n",
       "10   11                     Kerala    934,542  1,046,188       3.96%   \n",
       "11   12                      Delhi    881,336  1,014,688       3.73%   \n",
       "12   13                    Haryana    868,905    984,055       3.68%   \n",
       "13   14                     Odisha    662,886    753,177       2.81%   \n",
       "14   15                      Bihar    650,302    751,396       2.76%   \n",
       "15   16                     Punjab    617,192    676,164       2.62%   \n",
       "16   17                      Assam    411,454    493,167       1.74%   \n",
       "17   18               Chhattisgarh    410,525    464,399       1.74%   \n",
       "18   19                  Jharkhand    358,863    393,722       1.52%   \n",
       "19   20                Uttarakhand    267,143    303,781       1.13%   \n",
       "20   21            Jammu & Kashmir    193,352    224,226       0.82%   \n",
       "21   22           Himachal Pradesh    172,162    191,728       0.73%   \n",
       "22   23                        Goa     84,266     93,672       0.36%   \n",
       "23   24                    Tripura     62,550     72,636       0.27%   \n",
       "24   25                 Chandigarh     46,096     54,285       0.20%   \n",
       "25   26                 Puducherry     43,810     49,643       0.19%   \n",
       "26   27                  Meghalaya     38,785     42,697       0.16%   \n",
       "27   28                     Sikkim     37,557     42,756       0.16%   \n",
       "28   29                    Manipur     36,594          -       0.16%   \n",
       "29   30          Arunachal Pradesh     34,775     39,630       0.15%   \n",
       "30   31                   Nagaland     31,038     35,643       0.13%   \n",
       "31   32                    Mizoram     27,824          -       0.12%   \n",
       "32   33  Andaman & Nicobar Islands     10,371          -       0.04%   \n",
       "\n",
       "   GDP_Billion  \n",
       "0      414.928  \n",
       "1      276.522  \n",
       "2      264.080  \n",
       "3      263.747  \n",
       "4      257.484  \n",
       "5      177.456  \n",
       "6      159.334  \n",
       "7      153.324  \n",
       "8      150.084  \n",
       "9      145.913  \n",
       "10     124.764  \n",
       "11     117.660  \n",
       "12     116.001  \n",
       "13      88.497  \n",
       "14      86.817  \n",
       "15      82.397  \n",
       "16      54.930  \n",
       "17      54.806  \n",
       "18      47.909  \n",
       "19      35.664  \n",
       "20      25.813  \n",
       "21      22.984  \n",
       "22      11.250  \n",
       "23       8.351  \n",
       "24       6.154  \n",
       "25       5.849  \n",
       "26       5.178  \n",
       "27       5.014  \n",
       "28       4.885  \n",
       "29       4.643  \n",
       "30       4.144  \n",
       "31       3.715  \n",
       "32       1.385  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "def closebutton(delay):\n",
    "    \n",
    "    overlay_script = \"\"\"\n",
    "        var overlay = document.querySelector('#aswift_2_host');\n",
    "        if (overlay) {\n",
    "            overlay.parentNode.remove();\n",
    "        }\n",
    "    \"\"\"\n",
    "    driver.execute_script(overlay_script)\n",
    "    time.sleep(delay)\n",
    "\n",
    "# Initialize Selenium WebDriver (specify the path to your WebDriver)\n",
    "driver = webdriver.Chrome()  # Assuming Chrome WebDriver is used\n",
    "driver.get(' http://statisticstimes.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "Home=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[1]/button')\n",
    "Home.click()\n",
    "India1=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[1]/div/a[2]')\n",
    "India1.click()\n",
    "\n",
    "\n",
    "closebutton(5)\n",
    "\n",
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "\n",
    "economy.click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "India=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "India.click()\n",
    "\n",
    "Indian_state=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "Indian_state.click()\n",
    "\n",
    "\n",
    "#Main=driver.find_element(By.XPATH,'//section[@class=\"w-100 position-relative gap-between-section pb-0\"]')\n",
    "Table=driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]/tbody/tr')\n",
    "\n",
    "Rank  =[] \n",
    "State   =[]\n",
    "GDP_21_22  =[]\n",
    "GDP_22_22   =[]\n",
    "Share_21_22   =[]\n",
    "GDP_Billion   =[]\n",
    "\n",
    "\n",
    "for i in Table:\n",
    "    R=i.find_element(By.XPATH,'td[1]')\n",
    "    S=i.find_element(By.XPATH,'td[2]')\n",
    "    G1=i.find_element(By.XPATH,'td[5]')\n",
    "    G2=i.find_element(By.XPATH,'td[4]')\n",
    "    Sh=i.find_element(By.XPATH,'td[6]')\n",
    "    G3=i.find_element(By.XPATH,'td[7]')\n",
    "\n",
    "    Rank.append(R.text) \n",
    "    State.append(S.text)   \n",
    "    GDP_21_22.append(G1.text)  \n",
    "    GDP_22_22 .append(G2.text)\n",
    "    Share_21_22 .append(Sh.text)\n",
    "    GDP_Billion .append(G3.text)\n",
    "    \n",
    "# Create DataFrame from scraped data\n",
    "df = pd.DataFrame({\n",
    "    'Rank': Rank,\n",
    "\n",
    "    'State': State,\n",
    "    'GDP_21_22': GDP_21_22,\n",
    "    'GDP_22_23': GDP_22_22,\n",
    "    'Share_21_22':Share_21_22,\n",
    "    'GDP_Billion':GDP_Billion\n",
    "    \n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3219b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c3d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777f37c8",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.   \n",
    "Url = https://github.com/   \n",
    "You have to find the following details:   \n",
    "A) Repository title   \n",
    "B) Repository description   \n",
    "C) Contributors count   \n",
    "D) Language used  \n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e91897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>ContributorsCounts</th>\n",
       "      <th>Languages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dnhkng / GlaDOS</td>\n",
       "      <td>Personality Core</td>\n",
       "      <td>93</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TheOfficialFloW / PPPwn</td>\n",
       "      <td>PPPwn - PlayStation 4 PPPoE RCE</td>\n",
       "      <td>100</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>35,525</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fastfetch-cli / fastfetch</td>\n",
       "      <td>Like neofetch, but much faster because written...</td>\n",
       "      <td>157</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydralauncher / hydra</td>\n",
       "      <td>Hydra is a game launcher with its own embedded...</td>\n",
       "      <td>352</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TracecatHQ / tracecat</td>\n",
       "      <td>😼 The open source alternative to Tines / Splun...</td>\n",
       "      <td>85</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>coollabsio / coolify</td>\n",
       "      <td>An open-source &amp; self-hostable Heroku / Netlif...</td>\n",
       "      <td>786</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dylanaraps / neofetch</td>\n",
       "      <td>🖼️ A command-line system information tool writ...</td>\n",
       "      <td>1,542</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ItzCrazyKns / Perplexica</td>\n",
       "      <td>Perplexica is an AI-powered search engine. It ...</td>\n",
       "      <td>230</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Orange-OpenSource / hurl</td>\n",
       "      <td>Hurl, run and test HTTP requests with plain text.</td>\n",
       "      <td>427</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pagefaultgames / pokerogue</td>\n",
       "      <td>Not Found</td>\n",
       "      <td>399</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>penpot / penpot</td>\n",
       "      <td>Penpot: The open-source design tool for design...</td>\n",
       "      <td>1,328</td>\n",
       "      <td>Clojure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yangshun / tech-interview-handbook</td>\n",
       "      <td>💯 Curated coding interview preparation materia...</td>\n",
       "      <td>13,955</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dokploy / dokploy</td>\n",
       "      <td>Open Source Alternative to Vercel, Netlify and...</td>\n",
       "      <td>54</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>codecrafters-io / build-your-own-x</td>\n",
       "      <td>Master programming by recreating your favorite...</td>\n",
       "      <td>24,553</td>\n",
       "      <td>Not Found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xlang-ai / OSWorld</td>\n",
       "      <td>OSWorld: Benchmarking Multimodal Agents for Op...</td>\n",
       "      <td>90</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaiboWang / EasySpider</td>\n",
       "      <td>A visual no-code/code-free web crawler/spider易...</td>\n",
       "      <td>2,613</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trimstray / the-book-of-secret-knowledge</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>8,853</td>\n",
       "      <td>Not Found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pytorch / executorch</td>\n",
       "      <td>On-device AI across mobile, embedded and edge ...</td>\n",
       "      <td>173</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kelseyhightower / kubernetes-the-hard-way</td>\n",
       "      <td>Bootstrap Kubernetes the hard way. No scripts.</td>\n",
       "      <td>13,389</td>\n",
       "      <td>Not Found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MagicMirrorOrg / MagicMirror</td>\n",
       "      <td>MagicMirror² is an open source modular smart m...</td>\n",
       "      <td>4,121</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aptos-labs / aptos-core</td>\n",
       "      <td>Aptos is a layer 1 blockchain built to support...</td>\n",
       "      <td>3,516</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>idk10-a / aviator</td>\n",
       "      <td>Level up your Aviator game! This bot employs i...</td>\n",
       "      <td>30</td>\n",
       "      <td>Not Found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FRRouting / frr</td>\n",
       "      <td>The FRRouting Protocol Suite</td>\n",
       "      <td>1,168</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mdn / content</td>\n",
       "      <td>The content behind MDN Web Docs</td>\n",
       "      <td>22,396</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Titles  \\\n",
       "0                             dnhkng / GlaDOS   \n",
       "1                     TheOfficialFloW / PPPwn   \n",
       "2                 freeCodeCamp / freeCodeCamp   \n",
       "3                   fastfetch-cli / fastfetch   \n",
       "4                       hydralauncher / hydra   \n",
       "5                       TracecatHQ / tracecat   \n",
       "6                        coollabsio / coolify   \n",
       "7                       dylanaraps / neofetch   \n",
       "8                    ItzCrazyKns / Perplexica   \n",
       "9                    Orange-OpenSource / hurl   \n",
       "10                 pagefaultgames / pokerogue   \n",
       "11                            penpot / penpot   \n",
       "12         yangshun / tech-interview-handbook   \n",
       "13                          Dokploy / dokploy   \n",
       "14         codecrafters-io / build-your-own-x   \n",
       "15                         xlang-ai / OSWorld   \n",
       "16                     NaiboWang / EasySpider   \n",
       "17   trimstray / the-book-of-secret-knowledge   \n",
       "18                       pytorch / executorch   \n",
       "19  kelseyhightower / kubernetes-the-hard-way   \n",
       "20               MagicMirrorOrg / MagicMirror   \n",
       "21                    aptos-labs / aptos-core   \n",
       "22                          idk10-a / aviator   \n",
       "23                            FRRouting / frr   \n",
       "24                              mdn / content   \n",
       "\n",
       "                                         Descriptions ContributorsCounts  \\\n",
       "0                                    Personality Core                 93   \n",
       "1                     PPPwn - PlayStation 4 PPPoE RCE                100   \n",
       "2   freeCodeCamp.org's open-source codebase and cu...             35,525   \n",
       "3   Like neofetch, but much faster because written...                157   \n",
       "4   Hydra is a game launcher with its own embedded...                352   \n",
       "5   😼 The open source alternative to Tines / Splun...                 85   \n",
       "6   An open-source & self-hostable Heroku / Netlif...                786   \n",
       "7   🖼️ A command-line system information tool writ...              1,542   \n",
       "8   Perplexica is an AI-powered search engine. It ...                230   \n",
       "9   Hurl, run and test HTTP requests with plain text.                427   \n",
       "10                                          Not Found                399   \n",
       "11  Penpot: The open-source design tool for design...              1,328   \n",
       "12  💯 Curated coding interview preparation materia...             13,955   \n",
       "13  Open Source Alternative to Vercel, Netlify and...                 54   \n",
       "14  Master programming by recreating your favorite...             24,553   \n",
       "15  OSWorld: Benchmarking Multimodal Agents for Op...                 90   \n",
       "16  A visual no-code/code-free web crawler/spider易...              2,613   \n",
       "17  A collection of inspiring lists, manuals, chea...              8,853   \n",
       "18  On-device AI across mobile, embedded and edge ...                173   \n",
       "19     Bootstrap Kubernetes the hard way. No scripts.             13,389   \n",
       "20  MagicMirror² is an open source modular smart m...              4,121   \n",
       "21  Aptos is a layer 1 blockchain built to support...              3,516   \n",
       "22  Level up your Aviator game! This bot employs i...                 30   \n",
       "23                       The FRRouting Protocol Suite              1,168   \n",
       "24                    The content behind MDN Web Docs             22,396   \n",
       "\n",
       "     Languages  \n",
       "0       Python  \n",
       "1       Python  \n",
       "2   TypeScript  \n",
       "3            C  \n",
       "4   TypeScript  \n",
       "5   TypeScript  \n",
       "6          PHP  \n",
       "7        Shell  \n",
       "8   TypeScript  \n",
       "9         Rust  \n",
       "10  TypeScript  \n",
       "11     Clojure  \n",
       "12  TypeScript  \n",
       "13  TypeScript  \n",
       "14   Not Found  \n",
       "15      Python  \n",
       "16  JavaScript  \n",
       "17   Not Found  \n",
       "18         C++  \n",
       "19   Not Found  \n",
       "20  JavaScript  \n",
       "21        Rust  \n",
       "22   Not Found  \n",
       "23           C  \n",
       "24    Markdown  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://github.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "OpenSourceMenu=driver.find_element(By.XPATH,'//ul[@class=\"d-lg-flex list-style-none\"]/li[3]')\n",
    "OpenSourceMenu.click()\n",
    "TrendingMenu=driver.find_element(By.XPATH,'//a[@href=\"https://github.com/trending\"]')\n",
    "TrendingMenu.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Repositories=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]')\n",
    "\n",
    "def GetRepositoryData(dr,paramXp):\n",
    "    try:\n",
    "        retval=dr.find_element(By.XPATH, paramXp).text\n",
    "    except NoSuchElementException:\n",
    "        retval=\"Not Found\"\n",
    "    return retval\n",
    "\n",
    "Titles  =[] \n",
    "Descriptions   =[]\n",
    "ContributorsCounts =[]\n",
    "Languages   =[]\n",
    "\n",
    "for i in Repositories:\n",
    "    Title=GetRepositoryData(i,'h2')\n",
    "    Description=GetRepositoryData(i,'p')\n",
    "    ContributorsCount=GetRepositoryData(i,'div/a[2]')\n",
    "    Language=GetRepositoryData(i,'div/span/span[2]')\n",
    "\n",
    "    Titles.append(Title) \n",
    "    Descriptions.append(Description)   \n",
    "    ContributorsCounts.append(ContributorsCount)  \n",
    "    Languages.append(Language)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Titles': Titles,\n",
    "    'Descriptions': Descriptions,\n",
    "    'ContributorsCounts': ContributorsCounts,\n",
    "    'Languages': Languages\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b51408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1730b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fecd757",
   "metadata": {},
   "source": [
    " Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the \n",
    "following details:   \n",
    "A) Song name   \n",
    "B) Artist name   \n",
    "C) Last week rank   \n",
    "D) Peak rank   \n",
    "E) Weeks on board   \n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57956c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Aritst</th>\n",
       "      <th>Last_Rank</th>\n",
       "      <th>Peak Pos.</th>\n",
       "      <th>WKS on Chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fortnight</td>\n",
       "      <td>Taylor Swift Featuring Post Malone</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down Bad</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I Can Do It With A Broken Heart</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Tortured Poets Department</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So Long, London</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Us Vs. Them</td>\n",
       "      <td>$uicideBoy$</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wine Into Whiskey</td>\n",
       "      <td>Tucker Wetmore</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Spin You Around (1/24)</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Soak City</td>\n",
       "      <td>310babii</td>\n",
       "      <td>82</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Selfish</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>60</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Song                              Aritst  \\\n",
       "0                         Fortnight  Taylor Swift Featuring Post Malone   \n",
       "1                          Down Bad                        Taylor Swift   \n",
       "2   I Can Do It With A Broken Heart                        Taylor Swift   \n",
       "3     The Tortured Poets Department                        Taylor Swift   \n",
       "4                   So Long, London                        Taylor Swift   \n",
       "..                              ...                                 ...   \n",
       "95                      Us Vs. Them                         $uicideBoy$   \n",
       "96                Wine Into Whiskey                      Tucker Wetmore   \n",
       "97           Spin You Around (1/24)                       Morgan Wallen   \n",
       "98                        Soak City                            310babii   \n",
       "99                          Selfish                   Justin Timberlake   \n",
       "\n",
       "   Last_Rank Peak Pos. WKS on Chart  \n",
       "0          -         1            1  \n",
       "1          -         2            1  \n",
       "2          -         3            1  \n",
       "3          -         4            1  \n",
       "4          -         5            1  \n",
       "..       ...       ...          ...  \n",
       "95         -        96            1  \n",
       "96        84        77            5  \n",
       "97        89        24           13  \n",
       "98        82        53           19  \n",
       "99        60        19           13  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "url = \"https://github.com/\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Chart=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "Chart.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Songs_100=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "Songs_100.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "Songs_list=driver.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "\n",
    "def GetRepositoryData(dr,paramXp):\n",
    "    try:\n",
    "        retval=dr.find_element(By.XPATH, paramXp).text\n",
    "    except NoSuchElementException:\n",
    "        retval=\"Not Found\"\n",
    "    return retval\n",
    "\n",
    "Song  =[] \n",
    "Aritst   =[]\n",
    "Last_Rank =[]\n",
    "P_Pos   =[]\n",
    "W_Board=[]\n",
    "\n",
    "for i in Songs_list:\n",
    "    S=GetRepositoryData(i,'ul/li[4]/ul/li[1]/h3')\n",
    "    A=GetRepositoryData(i,'ul/li[4]/ul/li[1]/span')\n",
    "    L=GetRepositoryData(i,'ul/li[4]/ul/li[4]/span')\n",
    "    P=GetRepositoryData(i,'ul/li[4]/ul/li[5]/span')\n",
    "    W=GetRepositoryData(i,'ul/li[4]/ul/li[6]/span')\n",
    "\n",
    "    Song.append(S) \n",
    "    Aritst.append(A)   \n",
    "    Last_Rank.append(L)  \n",
    "    P_Pos.append(P)\n",
    "    W_Board.append(W)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Song': Song,\n",
    "    'Aritst': Aritst,\n",
    "    'Last_Rank': Last_Rank,\n",
    "    'Peak Pos.': P_Pos,\n",
    "    'WKS on Chart':W_Board\n",
    "    \n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaadb24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46dad6a8",
   "metadata": {},
   "source": [
    "Scrape the details of Highest selling novels.   \n",
    "A) Book name   \n",
    "B) Author name   \n",
    "C) Volumes sold   \n",
    "D) Publisher   \n",
    "E) Genre   \n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb70c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e94860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Book            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "         Sold        Publisher                        Genre  \n",
       "0   5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1   4,475,152       Bloomsbury           Children's Fiction  \n",
       "2   4,200,654       Bloomsbury           Children's Fiction  \n",
       "3   4,179,479       Bloomsbury           Children's Fiction  \n",
       "4   3,758,936     Random House              Romance & Sagas  \n",
       "..        ...              ...                          ...  \n",
       "95    807,311     Random House   General & Literary Fiction  \n",
       "96    794,201          Penguin        Food & Drink: General  \n",
       "97    792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98    791,507            Orion           Biography: General  \n",
       "99    791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Novel_list=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr')\n",
    "\n",
    "def GetRepositoryData(dr,paramXp):\n",
    "    try:\n",
    "        retval=dr.find_element(By.XPATH, paramXp).text\n",
    "    except NoSuchElementException:\n",
    "        retval=\"Not Found\"\n",
    "    return retval\n",
    "\n",
    "Book  =[] \n",
    "Author   =[]\n",
    "Sold =[]\n",
    "Publisher   =[]\n",
    "Genre=[]\n",
    "\n",
    "for i in Novel_list:\n",
    "    B=GetRepositoryData(i,'td[2]')\n",
    "    A=GetRepositoryData(i,'td[3]')\n",
    "    S=GetRepositoryData(i,'td[4]')\n",
    "    P=GetRepositoryData(i,'td[5]')\n",
    "    G=GetRepositoryData(i,'td[6]')\n",
    "\n",
    "    Book.append(B) \n",
    "    Author.append(A)   \n",
    "    Sold.append(S)  \n",
    "    Publisher.append(P)\n",
    "    Genre.append(G)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Book': Book,\n",
    "    'Author': Author,\n",
    "    'Sold': Sold,\n",
    "    'Publisher': Publisher,\n",
    "    'Genre':Genre\n",
    "    \n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d519f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52583810",
   "metadata": {},
   "source": [
    " Scrape the details most watched tv series of all time from imdb.com.   \n",
    "Url = https://www.imdb.com/list/ls512407256/ You have \n",
    "to find the following details:   \n",
    "A) Name   \n",
    "B) Year span   \n",
    "C) Genre   \n",
    "D) Run time   \n",
    "E) Ratings   \n",
    "F) Votes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e224dc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>60 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,286,747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,337,765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,082,983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>315,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>276,323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>657,071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>163,357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>115,948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>436,184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>139,850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name         Year                     Genre Run_Time  \\\n",
       "0        Game of Thrones  (2011–2019)  Action, Adventure, Drama   60 min   \n",
       "1        Stranger Things  (2016–2025)    Drama, Fantasy, Horror   60 min   \n",
       "2       The Walking Dead  (2010–2022)   Drama, Horror, Thriller   45 min   \n",
       "3         13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   60 min   \n",
       "4                The 100  (2014–2020)    Drama, Mystery, Sci-Fi   43 min   \n",
       "..                   ...          ...                       ...      ...   \n",
       "95        True Detective     (2014– )     Crime, Drama, Mystery   60 min   \n",
       "96             Teen Wolf  (2011–2017)    Action, Drama, Fantasy   41 min   \n",
       "97                The OA  (2016–2019)   Drama, Fantasy, Mystery   60 min   \n",
       "98          The Simpsons     (1989– )         Animation, Comedy   22 min   \n",
       "99  Desperate Housewives  (2004–2012)    Comedy, Drama, Mystery   45 min   \n",
       "\n",
       "   Ratings      Votes  \n",
       "0      9.2  2,286,747  \n",
       "1      8.7  1,337,765  \n",
       "2      8.1  1,082,983  \n",
       "3      7.5    315,681  \n",
       "4      7.6    276,323  \n",
       "..     ...        ...  \n",
       "95     8.9    657,071  \n",
       "96     7.7    163,357  \n",
       "97     7.8    115,948  \n",
       "98     8.7    436,184  \n",
       "99     7.6    139,850  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/list/ls512407256/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "Top_100=driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]')\n",
    "\n",
    "def GetRepositoryData(dr,paramXp):\n",
    "    try:\n",
    "        retval=dr.find_element(By.XPATH, paramXp).text\n",
    "    except NoSuchElementException:\n",
    "        retval=\"Not Found\"\n",
    "    return retval\n",
    "\n",
    "Name  =[] \n",
    "Year   =[]\n",
    "Genre =[]\n",
    "Run_Time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "for i in Top_100:\n",
    "    N=GetRepositoryData(i,'div[2]/h3/a')\n",
    "    Y=GetRepositoryData(i,'div[2]/h3/span[2]')\n",
    "    G=GetRepositoryData(i,'div[2]/p/span[5]')\n",
    "    RT=GetRepositoryData(i,'div[2]/p/span[3]')\n",
    "    R=GetRepositoryData(i,'div[2]/div/div/span[2]')\n",
    "    V=GetRepositoryData(i,'div[2]/p[4]/span[2]')\n",
    "\n",
    "    Name.append(N)   \n",
    "    Year.append(Y)  \n",
    "    Genre.append(G)\n",
    "    Run_Time.append(RT)\n",
    "    Ratings.append(R)\n",
    "    Votes.append(V)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': Name,\n",
    "    'Year': Year,\n",
    "    'Genre': Genre,\n",
    "    'Run_Time': Run_Time,\n",
    "    'Ratings':Ratings,\n",
    "    'Votes':Votes\n",
    "    \n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29877cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74a2f3e1",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.   \n",
    "Url = https://archive.ics.uci.edu/  You \n",
    "have to find the following details:   \n",
    "A) Dataset name   \n",
    "B) Data type   \n",
    "C) Task   \n",
    "D) Attribute type   \n",
    "E) No of instances   \n",
    "F) No of attribute \n",
    "G) Year   \n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b294fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>DYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Classification</td>\n",
       "      <td>A small classic dataset from Fisher, 1936. One...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Classification</td>\n",
       "      <td>4 databases: Cleveland, Hungary, Switzerland, ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>303 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Images of 13,611 grains of 7 different registe...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>13.61K Instances</td>\n",
       "      <td>16 Features</td>\n",
       "      <td>9/14/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>A total of 3810 rice grain's images were taken...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>3.81K Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>10/6/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Diagnostic Wisconsin Breast Cancer Database.</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>569 Instances</td>\n",
       "      <td>30 Features</td>\n",
       "      <td>11/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Images of the Kecimen and Besni raisin varieti...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>900 Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>8/14/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Using chemical analysis to determine the origi...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>178 Instances</td>\n",
       "      <td>13 Features</td>\n",
       "      <td>7/1/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Two datasets are included, related to red and ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.9K Instances</td>\n",
       "      <td>12 Features</td>\n",
       "      <td>10/7/2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Classification</td>\n",
       "      <td>This diabetes dataset is from AIM '94</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>1 Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bank Marketing</td>\n",
       "      <td>Classification</td>\n",
       "      <td>The data is related with direct marketing camp...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>45.21K Instances</td>\n",
       "      <td>17 Features</td>\n",
       "      <td>2/14/2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Derived from simple hierarchical decision mode...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1.73K Instances</td>\n",
       "      <td>6 Features</td>\n",
       "      <td>6/1/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Student Performance</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Predict student performance in secondary educa...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>649 Instances</td>\n",
       "      <td>33 Features</td>\n",
       "      <td>11/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Classification</td>\n",
       "      <td>From Audobon Society Field Guide; mushrooms de...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>8.12K Instances</td>\n",
       "      <td>22 Features</td>\n",
       "      <td>4/27/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Predict the age of abalone from physical measu...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>4.18K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>12/1/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Online Retail</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>This is a transnational data set which contain...</td>\n",
       "      <td>Multivariate, Sequential, Time-Series</td>\n",
       "      <td>541.91K Instances</td>\n",
       "      <td>8 Features</td>\n",
       "      <td>11/6/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Statlog (German Credit Data)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>This dataset classifies people described by a ...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>1K Instances</td>\n",
       "      <td>20 Features</td>\n",
       "      <td>11/17/1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Automobile</td>\n",
       "      <td>Regression</td>\n",
       "      <td>From 1985 Ward's Automotive Yearbook</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>205 Instances</td>\n",
       "      <td>25 Features</td>\n",
       "      <td>5/19/1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Census Income</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Predict whether income exceeds $50K/yr based o...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>48.84K Instances</td>\n",
       "      <td>14 Features</td>\n",
       "      <td>5/1/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Breast Cancer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>This breast cancer domain was obtained from th...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>286 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "      <td>7/11/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Predict Students' Dropout and Academic Success</td>\n",
       "      <td>Classification</td>\n",
       "      <td>A dataset created from a higher education inst...</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>4.42K Instances</td>\n",
       "      <td>36 Features</td>\n",
       "      <td>12/13/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Classifying Email as Spam or Non-Spam</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>4.6K Instances</td>\n",
       "      <td>57 Features</td>\n",
       "      <td>7/1/1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Auto MPG</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Revised from CMU StatLib library, data concern...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>398 Instances</td>\n",
       "      <td>7 Features</td>\n",
       "      <td>7/7/1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Breast Cancer Wisconsin (Original)</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Original Wisconsin Breast Cancer Database</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>699 Instances</td>\n",
       "      <td>9 Features</td>\n",
       "      <td>7/15/1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Air Quality</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Contains the responses of a gas multisensor de...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>9.36K Instances</td>\n",
       "      <td>15 Features</td>\n",
       "      <td>3/23/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Dataset_name  \\\n",
       "0                                             Iris   \n",
       "1                                    Heart Disease   \n",
       "2                                         Dry Bean   \n",
       "3                       Rice (Cammeo and Osmancik)   \n",
       "4                                            Adult   \n",
       "5             Breast Cancer Wisconsin (Diagnostic)   \n",
       "6                                           Raisin   \n",
       "7                                             Wine   \n",
       "8                                     Wine Quality   \n",
       "9                                         Diabetes   \n",
       "10                                  Bank Marketing   \n",
       "11                                  Car Evaluation   \n",
       "12                             Student Performance   \n",
       "13                                        Mushroom   \n",
       "14                                         Abalone   \n",
       "15                                   Online Retail   \n",
       "16                    Statlog (German Credit Data)   \n",
       "17                                      Automobile   \n",
       "18                                   Census Income   \n",
       "19                                   Breast Cancer   \n",
       "20  Predict Students' Dropout and Academic Success   \n",
       "21                                        Spambase   \n",
       "22                                        Auto MPG   \n",
       "23              Breast Cancer Wisconsin (Original)   \n",
       "24                                     Air Quality   \n",
       "\n",
       "                     Data_type  \\\n",
       "0               Classification   \n",
       "1               Classification   \n",
       "2               Classification   \n",
       "3               Classification   \n",
       "4               Classification   \n",
       "5               Classification   \n",
       "6               Classification   \n",
       "7               Classification   \n",
       "8   Classification, Regression   \n",
       "9               Classification   \n",
       "10              Classification   \n",
       "11              Classification   \n",
       "12  Classification, Regression   \n",
       "13              Classification   \n",
       "14  Classification, Regression   \n",
       "15  Classification, Clustering   \n",
       "16              Classification   \n",
       "17                  Regression   \n",
       "18              Classification   \n",
       "19              Classification   \n",
       "20              Classification   \n",
       "21              Classification   \n",
       "22                  Regression   \n",
       "23              Classification   \n",
       "24                  Regression   \n",
       "\n",
       "                                                 Task  \\\n",
       "0   A small classic dataset from Fisher, 1936. One...   \n",
       "1   4 databases: Cleveland, Hungary, Switzerland, ...   \n",
       "2   Images of 13,611 grains of 7 different registe...   \n",
       "3   A total of 3810 rice grain's images were taken...   \n",
       "4   Predict whether income exceeds $50K/yr based o...   \n",
       "5        Diagnostic Wisconsin Breast Cancer Database.   \n",
       "6   Images of the Kecimen and Besni raisin varieti...   \n",
       "7   Using chemical analysis to determine the origi...   \n",
       "8   Two datasets are included, related to red and ...   \n",
       "9               This diabetes dataset is from AIM '94   \n",
       "10  The data is related with direct marketing camp...   \n",
       "11  Derived from simple hierarchical decision mode...   \n",
       "12  Predict student performance in secondary educa...   \n",
       "13  From Audobon Society Field Guide; mushrooms de...   \n",
       "14  Predict the age of abalone from physical measu...   \n",
       "15  This is a transnational data set which contain...   \n",
       "16  This dataset classifies people described by a ...   \n",
       "17               From 1985 Ward's Automotive Yearbook   \n",
       "18  Predict whether income exceeds $50K/yr based o...   \n",
       "19  This breast cancer domain was obtained from th...   \n",
       "20  A dataset created from a higher education inst...   \n",
       "21              Classifying Email as Spam or Non-Spam   \n",
       "22  Revised from CMU StatLib library, data concern...   \n",
       "23          Original Wisconsin Breast Cancer Database   \n",
       "24  Contains the responses of a gas multisensor de...   \n",
       "\n",
       "                           Attribute_type    No_of_instances No_of_attribute  \\\n",
       "0                                 Tabular      150 Instances      4 Features   \n",
       "1                            Multivariate      303 Instances     13 Features   \n",
       "2                            Multivariate   13.61K Instances     16 Features   \n",
       "3                            Multivariate    3.81K Instances      7 Features   \n",
       "4                            Multivariate   48.84K Instances     14 Features   \n",
       "5                            Multivariate      569 Instances     30 Features   \n",
       "6                            Multivariate      900 Instances      8 Features   \n",
       "7                                 Tabular      178 Instances     13 Features   \n",
       "8                            Multivariate     4.9K Instances     12 Features   \n",
       "9               Multivariate, Time-Series        1 Instances     20 Features   \n",
       "10                           Multivariate   45.21K Instances     17 Features   \n",
       "11                           Multivariate    1.73K Instances      6 Features   \n",
       "12                           Multivariate      649 Instances     33 Features   \n",
       "13                           Multivariate    8.12K Instances     22 Features   \n",
       "14                                Tabular    4.18K Instances      8 Features   \n",
       "15  Multivariate, Sequential, Time-Series  541.91K Instances      8 Features   \n",
       "16                           Multivariate       1K Instances     20 Features   \n",
       "17                           Multivariate      205 Instances     25 Features   \n",
       "18                           Multivariate   48.84K Instances     14 Features   \n",
       "19                           Multivariate      286 Instances      9 Features   \n",
       "20                                Tabular    4.42K Instances     36 Features   \n",
       "21                           Multivariate     4.6K Instances     57 Features   \n",
       "22                           Multivariate      398 Instances      7 Features   \n",
       "23                           Multivariate      699 Instances      9 Features   \n",
       "24              Multivariate, Time-Series    9.36K Instances     15 Features   \n",
       "\n",
       "         DYear  \n",
       "0     7/1/1988  \n",
       "1     7/1/1988  \n",
       "2    9/14/2020  \n",
       "3    10/6/2019  \n",
       "4     5/1/1996  \n",
       "5    11/1/1995  \n",
       "6    8/14/2023  \n",
       "7     7/1/1991  \n",
       "8    10/7/2009  \n",
       "9          N/A  \n",
       "10   2/14/2012  \n",
       "11    6/1/1997  \n",
       "12  11/27/2014  \n",
       "13   4/27/1987  \n",
       "14   12/1/1995  \n",
       "15   11/6/2015  \n",
       "16  11/17/1994  \n",
       "17   5/19/1987  \n",
       "18    5/1/1996  \n",
       "19   7/11/1988  \n",
       "20  12/13/2021  \n",
       "21    7/1/1999  \n",
       "22    7/7/1993  \n",
       "23   7/15/1992  \n",
       "24   3/23/2016  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.maximize_window()\n",
    "time.sleep(3)\n",
    "\n",
    "View_DataSet=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "View_DataSet.click()\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "View_25=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select')\n",
    "View_25.send_keys('25')\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "#Expand=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]')\n",
    "#Expand.click()\n",
    "#driver.execute_script(\"window.scrollBy(0, 0);\")\n",
    "#time.sleep(3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Data_Sets=driver.find_elements(By.XPATH,'//div[@role=\"row\"]')\n",
    "\n",
    "\n",
    "def GetRepositoryData(dr,paramXp):\n",
    "    try:\n",
    "        retval=dr.find_element(By.XPATH, paramXp).text\n",
    "    except NoSuchElementException:\n",
    "        retval=\"Not Found\"\n",
    "    return retval\n",
    "\n",
    "Dataset_name=[]\n",
    "Data_type=[]   \n",
    "Task=[]   \n",
    "Attribute_type=[]   \n",
    "No_of_instances=[]   \n",
    "No_of_attribute=[] \n",
    "DYear=[]\n",
    "\n",
    "for i in Data_Sets:\n",
    "    i.click()\n",
    "    driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "    time.sleep(1)\n",
    "    DN=GetRepositoryData(i,'div/div[2]/h2/a')\n",
    "    DT=GetRepositoryData(i,'div/div[2]/div/div[1]/span')\n",
    "    T=GetRepositoryData(i,'div/div[2]/p')\n",
    "    AT=GetRepositoryData(i,'div/div[2]/div/div[2]/span')\n",
    "    NI=GetRepositoryData(i,'div/div[2]/div/div[3]/span')\n",
    "    NA=GetRepositoryData(i,'div/div[2]/div/div[4]/span')\n",
    "    DY=GetRepositoryData(i,'div[2]/div/table/tbody/tr/td[3]')\n",
    "\n",
    "    Dataset_name.append(DN)   \n",
    "    Data_type.append(DT)  \n",
    "    Task.append(T)\n",
    "    Attribute_type.append(AT)\n",
    "    No_of_instances.append(NI)\n",
    "    No_of_attribute.append(NA)\n",
    "    DYear.append(DY)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Dataset_name': Dataset_name,\n",
    "    'Data_type': Data_type,\n",
    "    'Task': Task,\n",
    "    'Attribute_type': Attribute_type,\n",
    "    'No_of_instances':No_of_instances,\n",
    "    'No_of_attribute':No_of_attribute,\n",
    "    'DYear':DYear\n",
    "    \n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1ecb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26d750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94055e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e649d0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8b405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ef3405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a4b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089052a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467b28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b6781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482ff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a34fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e256e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
